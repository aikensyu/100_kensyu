# ベクトルデータベース（Vector Database）完全解説

## 📊 ベクトルデータベースとは？

### 一言で説明すると
**ベクトルデータベース**は、**テキストや画像などのデータを数値の配列（ベクトル）として保存し、似ているものを高速に検索できる特殊なデータベース**です。

### 身近な例で理解する

#### 🎵 音楽配信サービスの例
```plaintext
あなたが「この曲に似た曲を聴きたい」とリクエストすると...

従来のデータベース：
❌ 「ジャンルが同じ」「アーティストが同じ」という単純な条件でしか検索できない

ベクトルデータベース：
✅ 曲のテンポ、メロディ、歌詞の雰囲気など複数の要素を数値化して
   「総合的に似ている曲」を瞬時に見つけられる
```

---

## 🤔 なぜベクトルデータベースが必要なのか？

### 1. **従来のデータベースの限界**

```sql
-- 従来のSQL検索
SELECT * FROM documents 
WHERE content LIKE '%人工知能%' 
  AND content LIKE '%機械学習%';
```
👎 **問題点**：
- 完全一致か部分一致しかできない
- 「AI」と「人工知能」が同じ意味だと理解できない
- 文脈や意味の類似性を判断できない

### 2. **ベクトルデータベースの強み**

```python
# ベクトルデータベースでの検索
query = "AIの最新トレンドを知りたい"
similar_docs = vector_db.similarity_search(query, k=5)

# 以下のような意味的に関連する文書が見つかる：
# - "人工知能の2024年の動向"
# - "機械学習の最新技術"
# - "ディープラーニングのブレークスルー"
```
👍 **メリット**：
- 意味の似ている内容を見つけられる
- 同義語や類義語を自動的に理解
- 文脈を考慮した検索が可能

---

## 🔢 ベクトルって何？

### ベクトルの基本概念

**ベクトル** = **特徴を数値の配列で表現したもの**

#### 例：果物をベクトルで表現
```python
# [甘さ, 酸味, 大きさ] という3次元ベクトル
apple  = [7, 3, 5]   # りんご：甘さ7、酸味3、大きさ5
orange = [6, 5, 4]   # みかん：甘さ6、酸味5、大きさ4
grape  = [8, 2, 1]   # ぶどう：甘さ8、酸味2、大きさ1

# りんごとみかんの距離（似ている度合い）を計算
distance = sqrt((7-6)² + (3-5)² + (5-4)²) = 2.45
```

### テキストのベクトル化（埋め込み/Embedding）

```python
# テキストを数値ベクトルに変換
text1 = "今日は良い天気です"
vector1 = [0.23, -0.45, 0.67, ..., 0.12]  # 768次元のベクトル

text2 = "今日は晴れています"  
vector2 = [0.25, -0.43, 0.65, ..., 0.14]  # 意味が似ているので近いベクトル

text3 = "プログラミングを学ぶ"
vector3 = [-0.82, 0.31, -0.29, ..., 0.91]  # 意味が違うので遠いベクトル
```

---

## 🏗️ ベクトルデータベースの仕組み

### 基本的な処理フロー

```mermaid
graph LR
    A[元のデータ<br/>テキスト/画像] --> B[埋め込みモデル<br/>Embedding Model]
    B --> C[ベクトル化<br/>[0.1, -0.3, ...]]
    C --> D[ベクトルDB<br/>保存]
    
    E[検索クエリ] --> F[埋め込みモデル]
    F --> G[クエリベクトル]
    G --> H[類似度計算]
    D --> H
    H --> I[類似文書<br/>Top-K取得]
```

### 主要なコンポーネント

#### 1. **埋め込みモデル（Embedding Model）**
```python
from sentence_transformers import SentenceTransformer

# 日本語対応の埋め込みモデル
model = SentenceTransformer('all-MiniLM-L6-v2')

# テキストをベクトルに変換
text = "人工知能の未来について"
vector = model.encode(text)  # 384次元のベクトル
print(f"ベクトルの次元数: {len(vector)}")  # 384
```

#### 2. **インデックス構造**
高速検索のためのデータ構造

- **Flat Index**: 全データと総当たりで比較（精度高いが遅い）
- **HNSW**: 階層的なグラフ構造（高速で精度も良い）
- **IVF**: クラスタリングベース（大規模データ向け）
- **LSH**: ハッシュベース（超高速だが精度は落ちる）

#### 3. **類似度メトリクス**
```python
# コサイン類似度（最も一般的）
def cosine_similarity(vec1, vec2):
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    return dot_product / (norm1 * norm2)

# ユークリッド距離
def euclidean_distance(vec1, vec2):
    return np.linalg.norm(vec1 - vec2)

# 内積（ドット積）
def dot_product(vec1, vec2):
    return np.dot(vec1, vec2)
```

---

## 🛠️ 主要なベクトルデータベース

### 1. **Pinecone** 🌲
```python
import pinecone

# 初期化
pinecone.init(api_key="your-api-key")
index = pinecone.Index("my-index")

# データの追加
index.upsert([
    ("doc1", [0.1, 0.2, 0.3], {"text": "AIについて"}),
    ("doc2", [0.4, 0.5, 0.6], {"text": "機械学習"})
])

# 検索
results = index.query([0.2, 0.3, 0.4], top_k=5)
```
**特徴**: フルマネージドサービス、スケーラブル、使いやすい

### 2. **Chroma** 🎨
```python
import chromadb

# クライアント作成
client = chromadb.Client()
collection = client.create_collection("my-collection")

# データの追加
collection.add(
    documents=["AIの基礎", "深層学習入門"],
    metadatas=[{"source": "book1"}, {"source": "book2"}],
    ids=["id1", "id2"]
)

# 検索
results = collection.query(
    query_texts=["人工知能について教えて"],
    n_results=2
)
```
**特徴**: オープンソース、軽量、ローカルでも動作

### 3. **Weaviate** 🔷
```python
import weaviate

# クライアント作成
client = weaviate.Client("http://localhost:8080")

# スキーマ定義
schema = {
    "class": "Article",
    "properties": [
        {"name": "title", "dataType": ["string"]},
        {"name": "content", "dataType": ["text"]}
    ]
}

# データの追加と検索
client.data_object.create(
    {"title": "AI入門", "content": "人工知能の基礎..."},
    "Article"
)
```
**特徴**: GraphQL API、ハイブリッド検索、スキーマ定義

### 4. **Faiss** 📚
```python
import faiss
import numpy as np

# インデックスの作成
dimension = 128
index = faiss.IndexFlatL2(dimension)

# ベクトルの追加
vectors = np.random.random((1000, dimension)).astype('float32')
index.add(vectors)

# 検索
query_vector = np.random.random((1, dimension)).astype('float32')
distances, indices = index.search(query_vector, k=5)
```
**特徴**: Meta(Facebook)製、超高速、大規模データ対応

### 5. **Qdrant** 🚀
```python
from qdrant_client import QdrantClient

# クライアント作成
client = QdrantClient("localhost", port=6333)

# コレクション作成
client.create_collection(
    collection_name="my_collection",
    vectors_config={"size": 384, "distance": "Cosine"}
)

# ポイントの追加
client.upsert(
    collection_name="my_collection",
    points=[
        {"id": 1, "vector": [0.1, 0.2, ...], "payload": {"text": "AI"}}
    ]
)
```
**特徴**: Rust製で高速、フィルタリング機能が強力

---

## 💡 実際の活用例

### 1. **RAGシステム（今回のサンプルコード）**
```python
# rag_sample.pyでの使用例
from langchain.vectorstores import Chroma

# ベクトルストアの作成
vector_store = Chroma.from_documents(
    documents=documents,
    embedding=embeddings,
    persist_directory="./chroma_db"
)

# 類似文書の検索
results = vector_store.similarity_search("RAGとは何ですか？", k=3)
```

### 2. **画像検索システム**
```python
# 画像をベクトル化して類似画像を検索
def find_similar_images(query_image):
    # 画像をベクトル化
    query_vector = image_model.encode(query_image)
    
    # ベクトルDBで検索
    similar_images = vector_db.search(query_vector, k=10)
    
    return similar_images
```

### 3. **レコメンデーションシステム**
```python
# ユーザーの行動履歴をベクトル化
user_vector = encode_user_behavior(user_history)

# 似た嗜好のユーザーを検索
similar_users = vector_db.find_similar(user_vector)

# おすすめアイテムを生成
recommendations = get_items_from_similar_users(similar_users)
```

### 4. **異常検知システム**
```python
# 正常データのベクトルクラスタを作成
normal_vectors = vector_db.get_cluster("normal")

# 新しいデータとの距離を計算
distance = calculate_distance(new_data_vector, normal_vectors)

# 距離が閾値を超えたら異常と判定
if distance > threshold:
    alert("異常を検知しました")
```

---

## ⚡ パフォーマンス比較

| データベース | 検索速度 | 精度 | スケーラビリティ | 料金 |
|------------|---------|------|----------------|------|
| **Pinecone** | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 有料 |
| **Chroma** | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ | 無料 |
| **Weaviate** | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | 無料/有料 |
| **Faiss** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 無料 |
| **Qdrant** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | 無料/有料 |

---

## 🎯 選択基準

### どのベクトルDBを選ぶべき？

#### **Pinecone**を選ぶ場合
- ✅ フルマネージドサービスが欲しい
- ✅ スケーラビリティが最重要
- ✅ 運用の手間を最小限にしたい

#### **Chroma**を選ぶ場合
- ✅ ローカル開発やプロトタイプ作成
- ✅ シンプルで使いやすいものが欲しい
- ✅ LangChainとの統合を重視

#### **Faiss**を選ぶ場合
- ✅ 超大規模データ（数億ベクトル）を扱う
- ✅ 最高のパフォーマンスが必要
- ✅ カスタマイズ性を重視

#### **Weaviate**を選ぶ場合
- ✅ GraphQLでクエリしたい
- ✅ ハイブリッド検索（ベクトル+キーワード）が必要
- ✅ スキーマ定義をしっかりしたい

#### **Qdrant**を選ぶ場合
- ✅ 高度なフィルタリングが必要
- ✅ Rust製の高速性を活かしたい
- ✅ プロダクション環境での安定性重視

---

## 🚀 実装のベストプラクティス

### 1. **適切な埋め込みモデルの選択**
```python
# 日本語テキストの場合
from sentence_transformers import SentenceTransformer

# 多言語対応モデル
model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')

# 日本語特化モデル
model = SentenceTransformer('sonoisa/sentence-bert-base-ja-mean-tokens-v2')
```

### 2. **チャンクサイズの最適化**
```python
# テキストを適切なサイズに分割
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=500,      # 小さすぎず大きすぎない
    chunk_overlap=50,    # 文脈を保持するためのオーバーラップ
    separators=["\n\n", "\n", "。", "、", " ", ""]
)
```

### 3. **メタデータの活用**
```python
# メタデータを追加して検索精度を向上
vector_store.add_texts(
    texts=["AIについての文書"],
    metadatas=[{
        "source": "technical_paper",
        "date": "2024-01-01",
        "author": "山田太郎",
        "category": "AI"
    }]
)

# メタデータでフィルタリング
results = vector_store.similarity_search(
    "AI",
    filter={"category": "AI", "date": {"$gte": "2024-01-01"}}
)
```

### 4. **インデックスの定期更新**
```python
# 新しいデータの追加とインデックスの再構築
def update_vector_store(new_documents):
    # 既存のベクトルストアをロード
    vector_store = load_vector_store()
    
    # 新しいドキュメントを追加
    vector_store.add_documents(new_documents)
    
    # インデックスを最適化（必要に応じて）
    vector_store.optimize_index()
    
    # 永続化
    vector_store.persist()
```

---

## 📈 今後のトレンド

### 1. **マルチモーダル検索**
テキスト、画像、音声を統合的に検索

### 2. **リアルタイムベクトル更新**
ストリーミングデータのリアルタイム処理

### 3. **ハイブリッド検索の進化**
ベクトル検索とキーワード検索の最適な組み合わせ

### 4. **エッジデバイスでの動作**
モバイルやIoTデバイスでのベクトル検索

---

## 🎓 まとめ

**ベクトルデータベース**は、**意味的な類似性を理解して検索できる次世代のデータベース**です。

### 覚えておくべきポイント

1. **従来のDBとの違い**: 完全一致ではなく「意味の近さ」で検索
2. **仕組み**: データを数値ベクトルに変換して保存・検索
3. **メリット**: 自然な検索、高速、スケーラブル
4. **用途**: RAG、画像検索、レコメンデーション、異常検知など
5. **選択**: 用途とスケールに応じて適切なDBを選ぶ

今回のRAGサンプルコード（`rag_sample.py`）では、**Chroma**を使ってローカルで簡単に試せるようにしています！

---

*この解説は2025年9月時点の情報に基づいています。*
