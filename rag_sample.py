"""
RAGï¼ˆRetrieval-Augmented Generationï¼‰ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰
æ¤œç´¢æ‹¡å¼µç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ä¾‹

å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:
pip install langchain openai chromadb tiktoken pypdf sentence-transformers
"""

import os
import json
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import hashlib

# LangChainã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
from langchain.prompts import PromptTemplate
from langchain.schema import Document

# è¿½åŠ ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
import numpy as np
from datetime import datetime


@dataclass
class RAGConfig:
    """RAGã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®š"""
    chunk_size: int = 1000
    chunk_overlap: int = 200
    top_k: int = 5
    temperature: float = 0.7
    model_name: str = "gpt-3.5-turbo"
    embedding_model: str = "sentence-transformers/all-MiniLM-L6-v2"
    persist_directory: str = "./chroma_db"


class SimpleRAGSystem:
    """
    ã‚·ãƒ³ãƒ—ãƒ«ãªRAGã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…
    ãƒ­ãƒ¼ã‚«ãƒ«ã§å‹•ä½œå¯èƒ½ãªè»½é‡ç‰ˆ
    """
    
    def __init__(self, config: RAGConfig = None):
        """
        RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
        
        Args:
            config: RAGè¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        self.config = config or RAGConfig()
        self.documents = []
        self.vector_store = None
        self.retriever = None
        self.qa_chain = None
        
        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆHuggingFaceã®ç„¡æ–™ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ï¼‰
        self.embeddings = HuggingFaceEmbeddings(
            model_name=self.config.embedding_model,
            model_kwargs={'device': 'cpu'}
        )
        
        print(f"âœ… RAGã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
        print(f"   - ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {self.config.chunk_size}")
        print(f"   - ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«: {self.config.embedding_model}")
    
    def load_documents(self, texts: List[str], metadata: List[Dict] = None):
        """
        ãƒ†ã‚­ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰
        
        Args:
            texts: ãƒ†ã‚­ã‚¹ãƒˆã®ãƒªã‚¹ãƒˆ
            metadata: å„ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        """
        if metadata is None:
            metadata = [{"source": f"document_{i}"} for i in range(len(texts))]
        
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ
        self.documents = [
            Document(page_content=text, metadata=meta)
            for text, meta in zip(texts, metadata)
        ]
        
        print(f"ğŸ“„ {len(self.documents)}å€‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸ")
        
        # ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†å‰²
        self._split_documents()
    
    def _split_documents(self):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.config.chunk_size,
            chunk_overlap=self.config.chunk_overlap,
            length_function=len,
            separators=["\n\n", "\n", "ã€‚", "ã€", " ", ""]
        )
        
        split_docs = text_splitter.split_documents(self.documents)
        self.documents = split_docs
        
        print(f"âœ‚ï¸  {len(split_docs)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã—ãŸ")
    
    def create_vector_store(self):
        """ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä½œæˆ"""
        print("ğŸ”„ ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä½œæˆä¸­...")
        
        # Chromaãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ä½œæˆ
        self.vector_store = Chroma.from_documents(
            documents=self.documents,
            embedding=self.embeddings,
            persist_directory=self.config.persist_directory
        )
        
        # æ°¸ç¶šåŒ–
        self.vector_store.persist()
        
        # ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã®è¨­å®š
        self.retriever = self.vector_store.as_retriever(
            search_type="similarity",
            search_kwargs={"k": self.config.top_k}
        )
        
        print(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä½œæˆã—ã¾ã—ãŸï¼ˆ{len(self.documents)}å€‹ã®ãƒ™ã‚¯ãƒˆãƒ«ï¼‰")
    
    def search(self, query: str, k: int = None) -> List[Document]:
        """
        é¡ä¼¼åº¦æ¤œç´¢ã‚’å®Ÿè¡Œ
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            k: è¿”ã™æ–‡æ›¸ã®æ•°
        
        Returns:
            é–¢é€£æ–‡æ›¸ã®ãƒªã‚¹ãƒˆ
        """
        if self.vector_store is None:
            raise ValueError("ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        k = k or self.config.top_k
        results = self.vector_store.similarity_search(query, k=k)
        
        return results
    
    def search_with_score(self, query: str, k: int = None) -> List[tuple]:
        """
        ã‚¹ã‚³ã‚¢ä»˜ãã§é¡ä¼¼åº¦æ¤œç´¢ã‚’å®Ÿè¡Œ
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            k: è¿”ã™æ–‡æ›¸ã®æ•°
        
        Returns:
            (æ–‡æ›¸, ã‚¹ã‚³ã‚¢)ã®ã‚¿ãƒ—ãƒ«ã®ãƒªã‚¹ãƒˆ
        """
        if self.vector_store is None:
            raise ValueError("ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        k = k or self.config.top_k
        results = self.vector_store.similarity_search_with_score(query, k=k)
        
        return results
    
    def generate_answer(self, query: str, context: List[str]) -> str:
        """
        ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åŸºã«å›ç­”ã‚’ç”Ÿæˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰
        
        Args:
            query: è³ªå•
            context: é–¢é€£æ–‡æ›¸ã®ãƒªã‚¹ãƒˆ
        
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸå›ç­”
        """
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        prompt_template = """
ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚
æƒ…å ±ã«ãªã„å†…å®¹ã«ã¤ã„ã¦ã¯ã€ã€Œæä¾›ã•ã‚ŒãŸæƒ…å ±ã«ã¯å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:
{context}

è³ªå•: {question}

å›ç­”: """
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®çµåˆ
        context_text = "\n\n".join(context)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
        prompt = prompt_template.format(
            context=context_text,
            question=query
        )
        
        # å®Ÿéš›ã®LLMå‘¼ã³å‡ºã—ã®ä»£ã‚ã‚Šã«ã€ãƒ‡ãƒ¢ç”¨ã®å›ç­”ã‚’ç”Ÿæˆ
        # æœ¬ç•ªç’°å¢ƒã§ã¯ã€ã“ã“ã§OpenAI APIã‚„ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚’å‘¼ã³å‡ºã—ã¾ã™
        demo_answer = f"""
è³ªå•ã€Œ{query}ã€ã«å¯¾ã™ã‚‹å›ç­”ï¼š

æä¾›ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦ã€ä»¥ä¸‹ã®æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼š
- {len(context)}å€‹ã®é–¢é€£æ–‡æ›¸ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
- æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„æƒ…å ±: {context[0][:100]}...

[æ³¨æ„: ã“ã‚Œã¯ãƒ‡ãƒ¢ç”¨ã®å›ç­”ã§ã™ã€‚å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€LLMãŒé©åˆ‡ãªå›ç­”ã‚’ç”Ÿæˆã—ã¾ã™]
"""
        
        return demo_answer
    
    def query(self, question: str) -> Dict[str, Any]:
        """
        RAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã‚’å®Ÿè¡Œ
        
        Args:
            question: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
        
        Returns:
            å›ç­”ã¨é–¢é€£æƒ…å ±ã‚’å«ã‚€è¾æ›¸
        """
        print(f"\nğŸ” è³ªå•: {question}")
        
        # 1. é–¢é€£æ–‡æ›¸ã®æ¤œç´¢
        relevant_docs = self.search_with_score(question)
        
        # 2. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æŠ½å‡º
        context = [doc.page_content for doc, score in relevant_docs]
        scores = [float(score) for doc, score in relevant_docs]
        
        # 3. å›ç­”ã®ç”Ÿæˆ
        answer = self.generate_answer(question, context)
        
        # 4. çµæœã®æ§‹ç¯‰
        result = {
            "question": question,
            "answer": answer,
            "source_documents": [
                {
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "similarity_score": float(score)
                }
                for doc, score in relevant_docs
            ],
            "timestamp": datetime.now().isoformat()
        }
        
        return result


class AdvancedRAGSystem(SimpleRAGSystem):
    """
    é«˜åº¦ãªRAGã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…
    è¿½åŠ æ©Ÿèƒ½: ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã€ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã€ã‚¯ã‚¨ãƒªæ‹¡å¼µ
    """
    
    def __init__(self, config: RAGConfig = None):
        super().__init__(config)
        self.query_history = []
        self.feedback_data = []
    
    def expand_query(self, query: str) -> List[str]:
        """
        ã‚¯ã‚¨ãƒªæ‹¡å¼µï¼šåŒç¾©èªã‚„é–¢é€£èªã‚’è¿½åŠ 
        
        Args:
            query: å…ƒã®ã‚¯ã‚¨ãƒª
        
        Returns:
            æ‹¡å¼µã•ã‚ŒãŸã‚¯ã‚¨ãƒªã®ãƒªã‚¹ãƒˆ
        """
        # ã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ä¾‹
        expanded_queries = [query]
        
        # ç°¡å˜ãªåŒç¾©èªè¾æ›¸ï¼ˆå®Ÿéš›ã¯å¤–éƒ¨APIã‚„è¾æ›¸ã‚’ä½¿ç”¨ï¼‰
        synonyms = {
            "RAG": ["Retrieval Augmented Generation", "æ¤œç´¢æ‹¡å¼µç”Ÿæˆ"],
            "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ": ["Agent", "è‡ªå¾‹ã‚·ã‚¹ãƒ†ãƒ "],
            "AI": ["äººå·¥çŸ¥èƒ½", "Artificial Intelligence"],
        }
        
        # ã‚¯ã‚¨ãƒªå†…ã®å˜èªã‚’åŒç¾©èªã§ç½®æ›
        for word, syns in synonyms.items():
            if word in query:
                for syn in syns:
                    expanded_queries.append(query.replace(word, syn))
        
        return expanded_queries
    
    def hybrid_search(self, query: str, k: int = None) -> List[Document]:
        """
        ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼šå¯†ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã®çµ„ã¿åˆã‚ã›
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            k: è¿”ã™æ–‡æ›¸ã®æ•°
        
        Returns:
            é–¢é€£æ–‡æ›¸ã®ãƒªã‚¹ãƒˆ
        """
        k = k or self.config.top_k
        
        # 1. å¯†ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
        vector_results = self.search(query, k=k*2)
        
        # 2. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªå®Ÿè£…ï¼‰
        keywords = query.lower().split()
        keyword_scores = []
        
        for doc in self.documents:
            score = sum(
                1 for keyword in keywords 
                if keyword in doc.page_content.lower()
            )
            if score > 0:
                keyword_scores.append((doc, score))
        
        # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        keyword_scores.sort(key=lambda x: x[1], reverse=True)
        keyword_results = [doc for doc, _ in keyword_scores[:k*2]]
        
        # 3. çµæœã®çµ±åˆã¨ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°
        combined_results = []
        seen_contents = set()
        
        # ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢çµæœã‚’å„ªå…ˆ
        for doc in vector_results:
            doc_hash = hashlib.md5(doc.page_content.encode()).hexdigest()
            if doc_hash not in seen_contents:
                combined_results.append(doc)
                seen_contents.add(doc_hash)
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢çµæœã‚’è¿½åŠ 
        for doc in keyword_results:
            doc_hash = hashlib.md5(doc.page_content.encode()).hexdigest()
            if doc_hash not in seen_contents and len(combined_results) < k:
                combined_results.append(doc)
                seen_contents.add(doc_hash)
        
        return combined_results[:k]
    
    def rerank_results(self, query: str, documents: List[Document]) -> List[Document]:
        """
        æ¤œç´¢çµæœã®ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°
        
        Args:
            query: å…ƒã®ã‚¯ã‚¨ãƒª
            documents: æ¤œç´¢çµæœã®æ–‡æ›¸ãƒªã‚¹ãƒˆ
        
        Returns:
            ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã•ã‚ŒãŸæ–‡æ›¸ãƒªã‚¹ãƒˆ
        """
        # ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚„ã‚ˆã‚Šé«˜åº¦ãªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’å®Ÿè£…
        # ã“ã“ã§ã¯ç°¡å˜ãªå®Ÿè£…ä¾‹
        
        scored_docs = []
        query_terms = set(query.lower().split())
        
        for doc in documents:
            # ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆã‚¯ã‚¨ãƒªã¨ã®é–¢é€£åº¦ï¼‰
            doc_terms = set(doc.page_content.lower().split())
            
            # Jaccardé¡ä¼¼åº¦
            intersection = query_terms.intersection(doc_terms)
            union = query_terms.union(doc_terms)
            jaccard_score = len(intersection) / len(union) if union else 0
            
            # æ–‡æ›¸é•·ã«ã‚ˆã‚‹ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆçŸ­ã™ãã‚‹ãƒ»é•·ã™ãã‚‹æ–‡æ›¸ã‚’é¿ã‘ã‚‹ï¼‰
            length_penalty = 1.0
            doc_length = len(doc.page_content)
            if doc_length < 50:
                length_penalty = 0.5
            elif doc_length > 2000:
                length_penalty = 0.8
            
            final_score = jaccard_score * length_penalty
            scored_docs.append((doc, final_score))
        
        # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        scored_docs.sort(key=lambda x: x[1], reverse=True)
        
        return [doc for doc, _ in scored_docs]
    
    def query_with_feedback(self, question: str, use_feedback: bool = True) -> Dict[str, Any]:
        """
        ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è€ƒæ…®ã—ãŸã‚¯ã‚¨ãƒªå®Ÿè¡Œ
        
        Args:
            question: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•
            use_feedback: ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã™ã‚‹ã‹
        
        Returns:
            å›ç­”ã¨é–¢é€£æƒ…å ±ã‚’å«ã‚€è¾æ›¸
        """
        # ã‚¯ã‚¨ãƒªæ‹¡å¼µ
        expanded_queries = self.expand_query(question)
        
        # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
        all_results = []
        for eq in expanded_queries:
            results = self.hybrid_search(eq)
            all_results.extend(results)
        
        # é‡è¤‡é™¤å»
        unique_results = []
        seen = set()
        for doc in all_results:
            doc_hash = hashlib.md5(doc.page_content.encode()).hexdigest()
            if doc_hash not in seen:
                unique_results.append(doc)
                seen.add(doc_hash)
        
        # ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°
        reranked_results = self.rerank_results(question, unique_results)
        
        # ä¸Šä½kä»¶ã‚’é¸æŠ
        final_results = reranked_results[:self.config.top_k]
        
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã¨å›ç­”ç”Ÿæˆ
        context = [doc.page_content for doc in final_results]
        answer = self.generate_answer(question, context)
        
        # å±¥æ­´ã«è¿½åŠ 
        self.query_history.append({
            "question": question,
            "timestamp": datetime.now().isoformat()
        })
        
        result = {
            "question": question,
            "answer": answer,
            "source_documents": [
                {
                    "content": doc.page_content,
                    "metadata": doc.metadata
                }
                for doc in final_results
            ],
            "expanded_queries": expanded_queries,
            "search_method": "hybrid",
            "timestamp": datetime.now().isoformat()
        }
        
        return result


# ========================================
# ä½¿ç”¨ä¾‹ã¨ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
# ========================================

def demo_simple_rag():
    """ã‚·ãƒ³ãƒ—ãƒ«ãªRAGã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢"""
    print("=" * 60)
    print("ğŸš€ ã‚·ãƒ³ãƒ—ãƒ«RAGã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢")
    print("=" * 60)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
    sample_documents = [
        """RAGï¼ˆRetrieval-Augmented Generationï¼‰ã¯ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®
        èƒ½åŠ›ã‚’æ‹¡å¼µã™ã‚‹æŠ€è¡“ã§ã™ã€‚å¤–éƒ¨ã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é–¢é€£æƒ…å ±ã‚’æ¤œç´¢ã—ã€
        ãã®æƒ…å ±ã‚’åŸºã«å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šæ­£ç¢ºã§æœ€æ–°ã®æƒ…å ±ã‚’æä¾›ã§ãã¾ã™ã€‚""",
        
        """AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€ç‰¹å®šã®ç›®æ¨™ã‚’é”æˆã™ã‚‹ãŸã‚ã«è‡ªå¾‹çš„ã«å‹•ä½œã™ã‚‹
        ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ç’°å¢ƒã‚’èªè­˜ã—ã€è¨ˆç”»ã‚’ç«‹ã¦ã€è¡Œå‹•ã‚’å®Ÿè¡Œã™ã‚‹
        èƒ½åŠ›ã‚’æŒã¡ã¾ã™ã€‚""",
        
        """ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¯ã€é«˜æ¬¡å…ƒãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹ç‡çš„ã«ä¿å­˜ã—ã€
        é¡ä¼¼åº¦æ¤œç´¢ã‚’é«˜é€Ÿã«å®Ÿè¡Œã™ã‚‹ãŸã‚ã®ç‰¹æ®Šãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§ã™ã€‚
        Chromaã€Pineconeã€Weaviateãªã©ãŒä»£è¡¨çš„ãªä¾‹ã§ã™ã€‚""",
        
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¯ã€AIãƒ¢ãƒ‡ãƒ«ã‹ã‚‰æœ›ã¾ã—ã„å‡ºåŠ›ã‚’å¾—ã‚‹ãŸã‚ã«ã€
        å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æœ€é©åŒ–ã™ã‚‹æŠ€è¡“ã§ã™ã€‚Few-shotå­¦ç¿’ã‚„Chain of Thought
        ãªã©ã®æ‰‹æ³•ãŒã‚ã‚Šã¾ã™ã€‚""",
        
        """LangChainã¯ã€LLMã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºã®ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚
        ãƒã‚§ãƒ¼ãƒ³ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ãƒ¡ãƒ¢ãƒªã€ãƒ„ãƒ¼ãƒ«ãªã©ã®æ¦‚å¿µã‚’æä¾›ã—ã€
        è¤‡é›‘ãªAIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æ§‹ç¯‰ã‚’å®¹æ˜“ã«ã—ã¾ã™ã€‚"""
    ]
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 
    metadata = [
        {"source": "rag_basics.pdf", "page": 1},
        {"source": "ai_agents.pdf", "page": 5},
        {"source": "vector_db_guide.pdf", "page": 3},
        {"source": "prompt_engineering.pdf", "page": 2},
        {"source": "langchain_docs.pdf", "page": 10}
    ]
    
    # RAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    rag = SimpleRAGSystem()
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ­ãƒ¼ãƒ‰
    rag.load_documents(sample_documents, metadata)
    
    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ä½œæˆ
    rag.create_vector_store()
    
    # è³ªå•å¿œç­”ã®ãƒ†ã‚¹ãƒˆ
    test_questions = [
        "RAGã¨ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç‰¹å¾´ã‚’æ•™ãˆã¦ãã ã•ã„",
        "ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¾‹ã‚’æŒ™ã’ã¦ãã ã•ã„"
    ]
    
    for question in test_questions:
        print("\n" + "=" * 40)
        result = rag.query(question)
        
        print(f"ğŸ“Œ è³ªå•: {result['question']}")
        print(f"ğŸ’¬ å›ç­”:\n{result['answer'][:200]}...")
        print(f"ğŸ“š å‚ç…§ã—ãŸæ–‡æ›¸æ•°: {len(result['source_documents'])}")
        
        # æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„æ–‡æ›¸ã‚’è¡¨ç¤º
        if result['source_documents']:
            top_doc = result['source_documents'][0]
            print(f"ğŸ“„ æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„æ–‡æ›¸:")
            print(f"   - ã‚½ãƒ¼ã‚¹: {top_doc['metadata'].get('source', 'N/A')}")
            print(f"   - ã‚¹ã‚³ã‚¢: {top_doc.get('similarity_score', 'N/A'):.3f}")


def demo_advanced_rag():
    """é«˜åº¦ãªRAGã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢"""
    print("\n" + "=" * 60)
    print("ğŸš€ é«˜åº¦ãªRAGã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢")
    print("=" * 60)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆã‚ˆã‚Šè©³ç´°ï¼‰
    advanced_documents = [
        """æ©Ÿæ¢°å­¦ç¿’ã«ãŠã‘ã‚‹æ•™å¸«ã‚ã‚Šå­¦ç¿’ã¯ã€ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚
        åˆ†é¡å•é¡Œã¨å›å¸°å•é¡ŒãŒä¸»ãªå¿œç”¨ä¾‹ã§ã€æ±ºå®šæœ¨ã€ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã€
        ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼ãƒã‚·ãƒ³ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãªã©ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚""",
        
        """æ·±å±¤å­¦ç¿’ã¯ã€å¤šå±¤ã®ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã™ã‚‹æ©Ÿæ¢°å­¦ç¿’ã®ä¸€åˆ†é‡ã§ã™ã€‚
        CNNï¼ˆç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã¯ç”»åƒèªè­˜ã«ã€
        RNNï¼ˆå†å¸°å‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼‰ã¯æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«ã€
        Transformerã¯è‡ªç„¶è¨€èªå‡¦ç†ã«ç‰¹ã«åŠ¹æœçš„ã§ã™ã€‚""",
        
        """è‡ªç„¶è¨€èªå‡¦ç†ï¼ˆNLPï¼‰ã¯ã€äººé–“ã®è¨€èªã‚’ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã§å‡¦ç†ã™ã‚‹æŠ€è¡“ã§ã™ã€‚
        ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã€å“è©ã‚¿ã‚°ä»˜ã‘ã€å›ºæœ‰è¡¨ç¾èªè­˜ã€æ„Ÿæƒ…åˆ†æã€æ©Ÿæ¢°ç¿»è¨³ã€
        è³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ãªã©ã€æ§˜ã€…ãªã‚¿ã‚¹ã‚¯ãŒå«ã¾ã‚Œã¾ã™ã€‚""",
        
        """å¼·åŒ–å­¦ç¿’ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç’°å¢ƒã¨ã®ç›¸äº’ä½œç”¨ã‚’é€šã˜ã¦æœ€é©ãªè¡Œå‹•ã‚’å­¦ç¿’ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚
        Qå­¦ç¿’ã€SARSAã€Deep Q-Networkï¼ˆDQNï¼‰ã€Policy Gradientã€
        Actor-Criticãªã©ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãŒã‚ã‚Šã¾ã™ã€‚"""
    ]
    
    # é«˜åº¦ãªRAGã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–
    advanced_rag = AdvancedRAGSystem()
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ­ãƒ¼ãƒ‰
    advanced_rag.load_documents(advanced_documents)
    
    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ä½œæˆ
    advanced_rag.create_vector_store()
    
    # ã‚¯ã‚¨ãƒªæ‹¡å¼µã¨ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã®ãƒ†ã‚¹ãƒˆ
    test_query = "æ·±å±¤å­¦ç¿’ã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„"
    
    print(f"\nğŸ“ å…ƒã®ã‚¯ã‚¨ãƒª: {test_query}")
    
    # ã‚¯ã‚¨ãƒªæ‹¡å¼µ
    expanded = advanced_rag.expand_query(test_query)
    print(f"ğŸ“ˆ æ‹¡å¼µã•ã‚ŒãŸã‚¯ã‚¨ãƒª: {expanded}")
    
    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã®å®Ÿè¡Œ
    result = advanced_rag.query_with_feedback(test_query)
    
    print(f"\nğŸ’¬ å›ç­”:\n{result['answer'][:300]}...")
    print(f"ğŸ” æ¤œç´¢æ–¹æ³•: {result['search_method']}")
    print(f"ğŸ“š å‚ç…§ã—ãŸæ–‡æ›¸æ•°: {len(result['source_documents'])}")


def save_rag_results(results: Dict[str, Any], filename: str = "rag_results.json"):
    """RAGã®çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ çµæœã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")


# ========================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨åˆ†
# ========================================

if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘     RAG (Retrieval-Augmented Generation) Demo        â•‘
    â•‘          æ¤œç´¢æ‹¡å¼µç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®ã‚µãƒ³ãƒ—ãƒ«                  â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # ã‚·ãƒ³ãƒ—ãƒ«ãªRAGã®ãƒ‡ãƒ¢
    demo_simple_rag()
    
    # é«˜åº¦ãªRAGã®ãƒ‡ãƒ¢
    demo_advanced_rag()
    
    print("\n" + "=" * 60)
    print("âœ… ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†ï¼")
    print("=" * 60)
    
    # ã‚«ã‚¹ã‚¿ãƒ ä½¿ç”¨ä¾‹
    print("\nğŸ“˜ ã‚«ã‚¹ã‚¿ãƒ ä½¿ç”¨ä¾‹:")
    print("""
    # ã‚ãªãŸã®ã‚³ãƒ¼ãƒ‰ã§RAGã‚’ä½¿ç”¨ã™ã‚‹ä¾‹:
    
    from rag_sample import SimpleRAGSystem
    
    # åˆæœŸåŒ–
    rag = SimpleRAGSystem()
    
    # ã‚ãªãŸã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰
    my_documents = ["æ–‡æ›¸1ã®å†…å®¹", "æ–‡æ›¸2ã®å†…å®¹", ...]
    rag.load_documents(my_documents)
    
    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä½œæˆ
    rag.create_vector_store()
    
    # è³ªå•å¿œç­”
    result = rag.query("ã‚ãªãŸã®è³ªå•")
    print(result['answer'])
    """)
    
    print("\nğŸ‰ RAGã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ã£ã¦ã€çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’æ´»ç”¨ã—ãŸ")
    print("   é«˜åº¦ãªè³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¦ãã ã•ã„ï¼")
